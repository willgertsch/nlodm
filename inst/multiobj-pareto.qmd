---
title: "Multi-objective design using Pareto fronts"
format: html
editor: visual
---

```{r setup}
devtools::load_all(".")
library(ggplot2)
library(dplyr)
library(tidyr)
library(drc)
library(GGally)
```

## Introduction

Use deguelin data as an example and fit a 4 parameter log-logistic.

```{r}
#mod = drm(r/n ~ dose, weights=n, data=deguelin, fct=LL.4(), type='binomial')
# going to fit a 3 parameter model instead
mod = drm(r/n ~ dose, weights=n, data=deguelin, fct=LL.3u(), type='binomial')
```

```{r}
coef(mod)
```

```{r}
pred_data = data.frame(
  dose = seq(0, 50)
) %>%
  mutate(yhat = predict(mod, newdata = data.frame(dose)))

pred_data %>%
  ggplot(aes(x = dose, y = yhat)) +
  geom_line(color = 'blue') +
  geom_point(data=drc::deguelin, aes(x = dose, y = r/n), color = 'black') +
  theme_bw() +
  labs(y = 'P(death)', title = 'Effect of deguelin on Macrosiphoniella sanborni')
```

The model used by the drc package has the following form. $$
f(x) = c + \frac{1-c}{1+\exp(b(\log(x)-\log(e)))}
$$ My optimal design code uses the parameterization in BMDS. $$
f(x) = g + \frac{1-g}{1 + \exp(-a -b\log(x))}
$$ Need to convert from one parameterization to the other

```{r}
# b, c, e
theta0 = as.numeric(coef(mod))
# g, a, b
theta = c(theta0[2], theta0[1]*log(theta0[3]), -theta0[1])
```

Plot to check if correct.

```{r}
data.frame(
  dose = seq(0, 50)
) %>%
  mutate(yhat = theta[1] + (1-theta[1])/(1+exp(-theta[2]-theta[3]*log(dose)))) %>%
  ggplot(aes(x = dose, y = yhat)) +
  geom_line()
```

## Multi-objective optimization

## Designs for multiple criteria

### D and A

Find single objective designs first.

```{r}
# objective value for uniform design with 3 design points
eval_crit(
  x = seq(0.001, 50, length.out=3),
  w = rep(1/4, 3),
  grad_fun = grad.loglogistic,
  obj_fun = obj.A,
  theta = theta,
  param = c(),
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
D_opt = nlodm(
  grad_fun = grad.loglogistic,
  obj = "D",
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 100,
  iter = 500,
  seed = 423,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
D_opt$plot
```

```{r}
D_opt$design
```

```{r, results='hide'}
# produces NaN's from binary_response = T
A_opt = nlodm(
  grad_fun = grad.loglogistic,
  obj = "A",
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 100,
  iter = 500,
  seed = 423,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
A_opt$plot
```

```{r}
A_opt$design
```

```{r, results='hide'}
grad_funs = list(grad.loglogistic, grad.loglogistic)
obj_funs = list(obj.D, obj.A)
thetas = list(
    theta,
    theta
  )
params = list(
    c(),
    c()
  )
binary_responses = c(T,T)
dr_funs = list(f.loglogistic3.bmds, f.loglogistic3.bmds)

result = multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
pareto_data = extract_front(result)
plot_pareto2d(pareto_data, c("D", "A")) +
  geom_vline(xintercept = 7.717531) +
  geom_hline(yintercept = 1546.254)
```

```{r}
# pareto front with scaled objective values
# changes to maximization format
extract_front(result) %>%
  mutate(obj1 = 7.717531/obj1, obj2 = 1546.254/obj2) %>%
  plot_pareto2d(c("D", "A")) +
  geom_smooth(se=F, linetype=2, color='grey')
```

This plot suggests that getting a good design for A is more difficult.

Suppose we want designs with \>0.98 on D and \>0.90 on A. These designs are roughly the same so we can just take the one with the best performance on the A objective.

```{r}
extract_front(result) %>%
  mutate(obj1 = 7.717531/obj1, obj2 = 1546.254/obj2) %>%
  filter(obj1 > 0.98, obj2 > 0.90) %>% 
  arrange(desc(obj2)) %>%
  head(1)
```

This design no longer has equal weights, but not as extreme as the A optimal design. The highest dose is inbetween the D-optimal highest dose the the A-optimal higest dose.

### Continuous vs binary response

```{r}
D_opt_cont = nlodm(
  grad_fun = grad.loglogistic,
  obj = "D",
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 100,
  iter = 500,
  seed = 423,
  binary_response = F,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
D_opt$design
```

```{r}
D_opt_cont$design
```

The biggest difference between these designs is that assuming the binary response requires the 3rd point to be further out. This is probably because the variance in non-constant and more information is needed at higher doses.

Now try the Pareto-optimal approach.

```{r}
grad_funs = list(grad.loglogistic, grad.loglogistic)
obj_funs = list(obj.D, obj.D)
thetas = list(
    theta,
    theta
  )
params = list(
    c(),
    c()
  )
binary_responses = c(T,F)
dr_funs = list(f.loglogistic3.bmds, f.loglogistic3.bmds)

result = multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
# front with optimal objective values overlayed
pareto_data = extract_front(result)
plot_pareto2d(pareto_data, c("D binary", "D continuous")) +
  geom_vline(xintercept = 7.717531) +# optimal binary
  geom_hline(yintercept = 12.81728) +# optimal continuous
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

```{r}
# pareto front with scaled objective values
# changes to maximization format
extract_front(result) %>%
  mutate(obj1 = 7.717531/obj1, obj2 = 12.81728/obj2) %>%
  plot_pareto2d(c("D binary", "D continuous")) +
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

From this plot we see that we can get designs with very high efficiency on both objectives. We can get the designs with efficiency requirements on each objectives.

```{r}
extract_front(result) %>%
  mutate(obj1 = 7.717531/obj1, obj2 = 12.81728/obj2) %>%
  filter(obj1 > 0.99, obj2 > 0.99)
```

It seems that having the high dose at around 27 is a good solution for managing the tradeoffs between a continuous and binary response assumption.

### D and BMD
Finding the c-optimal design for the BMD.
```{r}
bmd_grad = get_bmd_grad("Log-logistic", 'extra')
c = matrix(bmd_grad(0.1, theta), nrow = 1)
out_copt_bmd = nlodm(
  grad_fun = grad.loglogistic,
  obj = 'c',
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  c = c,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```
```{r}
out_copt_bmd$design
```

```{r}
out_copt_bmd$plot
```

In my previous paper/web-app, I found designs for estimating the BMD using a compound design criteria.

```{r}
# set lambda = 0.5
out_compound = nlodm(
  model = 'Log-logistic',
  grad_fun = grad.loglogistic,
  obj = 'bmd',
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  bmd_type = 'extra',
  risk = 0.1,
  lambda = 0.5,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
out_compound$plot
```

```{r}
out_compound$design
```

We had to choose $\lambda$ in order to get this result. To see how the choice of $\lambda$ affects the design, we can find the design for different values of $\lambda$ and plot the efficiencies.

```{r}
lambdas = seq(0, 1, length.out=10)
bmd_grad = get_bmd_grad("Log-logistic", 'extra')
c = matrix(bmd_grad(0.1, theta), nrow = 1)
Dvals = numeric(length(lambdas))
Cvals = numeric(length(lambdas))
for (i in 1:length(lambdas)) {
  
  # find the design
  out_i = nlodm(
  model = 'Log-logistic',
  grad_fun = grad.loglogistic,
  obj = 'bmd',
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  bmd_type = 'extra',
  risk = 0.1,
  lambda = lambdas[i],
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
  )
  
  # save objective values
  Dvals[i] = eval_crit(
    out_i$design$x,
    out_i$design$w,
    grad.loglogistic,
    obj.D,
    theta,
    c(),
    T,
    f.loglogistic3.bmds
  )
  
  Cvals[i] = eval_crit(
    out_i$design$x,
    out_i$design$w,
    grad.loglogistic,
    obj.c,
    theta,
    c,
    T,
    f.loglogistic3.bmds
  )
}
```

```{r}
data.frame(
  Dvals,
  Cvals
) %>%
  ggplot(aes(x=Dvals, y = Cvals)) +
  geom_point() + 
  geom_smooth(se = F, linetype = 2, color = 'grey') +
  theme_bw() +
  geom_vline(xintercept = -7.717531)
```

```{r}
data.frame(
  Dvals,
  Cvals
) %>%
  mutate(
    obj1 = max(Dvals)/Dvals,
    obj2 = max(Cvals)/Cvals
  ) %>%
  ggplot(aes(x = obj1, y = obj2)) +
  geom_point(color = 'blue') +
  geom_smooth(se = F, linetype = 2, color = 'grey') +
  theme_bw()
```

```{r}
data.frame(
  Dvals,
  Cvals
) %>%
  mutate(
    obj1 = max(Dvals)/Dvals,
    obj2 = max(Cvals)/Cvals
  )
```

Find the c-optimal design for estimating the BMD.

```{r}
bmd_grad = get_bmd_grad("Log-logistic", 'extra')
c = bmd_grad(0.1, theta)
out_bmd_c = nlodm(
  model = 'Log-logistic',
  grad_fun = grad.loglogistic,
  obj = 'c',
  c = c,
  theta = theta,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  bmd_type = 'extra',
  risk = 0.1,
  lambda = 1,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
out_bmd_c$plot
```

```{r}
out_bmd_c$design
```

Now use the Pareto-front approach and compare.

```{r}
bmd_grad = get_bmd_grad("Log-logistic", 'extra')
c = bmd_grad(0.1, theta)
grad_funs = list(grad.loglogistic, grad.loglogistic)
obj_funs = list(obj.D, obj.c)
thetas = list(
    theta,
    theta
  )
params = list(
    c(),
    c
  )
binary_responses = c(T,T)
dr_funs = list(f.loglogistic3.bmds, f.loglogistic3.bmds)

result = multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
extract_front(result) %>%
  plot_pareto2d( c('D', 'BMD')) +
  geom_vline(xintercept = 7.717531) +
  geom_hline(yintercept = 6.471296) +
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

```{r}
extract_front(result) %>%
  mutate(
    obj1 = 7.717531/obj1,
    obj2 = 6.471296/obj2
  ) %>%
  plot_pareto2d( c('D', 'BMD')) +
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

From this plot it looks like the D and BMD objectives have similar design needs.

```{r}
extract_front(result) %>%
  mutate(
    obj1 = 7.717531/obj1,
    obj2 = 6.471296/obj2
  ) %>%
  filter(obj1 > 0.9887, obj2 > 0.99)
```

Therefore, it seems that is best to design for BMD because the design will still be very good at the D objective.

Compare with compound designs found earlier.

```{r}
extract_front(result) %>%
  mutate(
    obj1 = 7.717531/obj1,
    obj2 = 6.471296/obj2
  ) %>%
  plot_pareto2d( c('D', 'BMD')) +
  geom_smooth(se = F, linetype = 2, color = 'grey') +
  geom_point(data = data.frame(obj1=7.717531/-Dvals, obj2=6.471296/-Cvals), aes(x=obj1, y=obj2), color='red') +
geom_smooth(data = data.frame(obj1=7.717531/-Dvals, obj2=6.471296/-Cvals), aes(x=obj1, y=obj2), color='black', se = F)
```

This seems to suggest that the efficiency plots from Cook and Wong (1994) roughly correspond to the Pareto front.

## Designs with prior information

The usual optimal design approach for the problem of local parameter values is either Bayesian designs or minimax designs. However, we can also apply a Pareto optimal approach. We will compare

### 2 prior theta

What if the background response is 0?

```{r}
theta1 = theta
theta2 = c(0.0001, -12.0933906,   4.1368052)
# have to add a small constant or design is singular

data.frame(
  dose = seq(0, 50)
) %>%
  mutate(
    yhat1 = f.loglogistic3.bmds(dose, theta1),
    yhat2 = f.loglogistic3.bmds(dose, theta2)
  ) %>%
  ggplot(aes(x = dose)) +
  geom_line(aes(y = yhat1)) +
  geom_line(aes(y = yhat2)) +
  theme_bw() +
  labs(title = "Dose-response curve variety", y = 'P(death)')
```

Start with single objective.

```{r}
out_theta1 = nlodm(
  model = 'Log-logistic',
  grad_fun = grad.loglogistic,
  obj = 'D',
  theta = theta1,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
out_theta2 = nlodm(
  model = 'Log-logistic',
  grad_fun = grad.loglogistic,
  obj = 'D',
  theta = theta2,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
grad_funs = list(grad.loglogistic, grad.loglogistic)
obj_funs = list(obj.D, obj.D)
thetas = list(
    theta1,
    theta2
  )
params = list(
    c(),
    c()
  )
binary_responses = c(T,T)
dr_funs = list(f.loglogistic3.bmds, f.loglogistic3.bmds)

result = multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
extract_front(result) %>%
  mutate(
    obj1 = obj1,
    obj2 = obj2
  ) %>%
  plot_pareto2d( c('D theta 1', 'D theta 2')) +
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

```{r}
extract_front(result) %>%
  mutate(
    obj1 = (max(obj1)-obj1)/(max(obj1)-min(obj1)),
    obj2 = (max(obj2)-obj2)/(max(obj2)-min(obj2))
  ) %>%
  plot_pareto2d( c('D theta 1', 'D theta 2')) +
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

It seems that it is harder to have a design that is efficient for estimating the case when the background dose is 0.

### 3 prior theta

Add another theta, this time tweak the slope

```{r}
theta1 = theta
theta2 = c(0.0001, -12.0933906,   4.1368052)
# have to add a small constant or design is singular
theta3 = c(0.3238014, -15, 4.1368052)

data.frame(
  dose = seq(0, 50)
) %>%
  mutate(
    yhat1 = f.loglogistic3.bmds(dose, theta1),
    yhat2 = f.loglogistic3.bmds(dose, theta2),
    yhat3 = f.loglogistic3.bmds(dose, theta3)
  ) %>%
  ggplot(aes(x = dose)) +
  geom_line(aes(y = yhat1)) +
  geom_line(aes(y = yhat2)) +
  geom_line(aes(y = yhat3)) + 
  theme_bw() +
  labs(title = "Dose-response curve variety", y = 'P(death)')
```

```{r}
# check the new value
out_theta3 = nlodm(
  model = 'Log-logistic',
  grad_fun = grad.loglogistic,
  obj = 'D',
  theta = theta3,
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 50,
  iter = 500,
  seed = 1234,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
grad_funs = list(grad.loglogistic, grad.loglogistic, grad.loglogistic)
obj_funs = list(obj.D, obj.D, obj.D)
thetas = list(
    theta1,
    theta2,
    theta3
  )
params = list(
    c(),
    c(),
    c()
  )
binary_responses = c(T,T, T)
dr_funs = list(f.loglogistic3.bmds, f.loglogistic3.bmds, f.loglogistic3.bmds)

result = multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
library(plotly)
fig = plot_ly(extract_front(result), x = ~scale_obj(obj1), 
              y = ~scale_obj(obj2), 
              z = ~scale_obj(obj3),
              type = 'scatter3d')
fig
```

From this plot, it seems that obj1 and obj2 cluster together and obj3 is more different.

```{r}
extract_front(result) %>%
  mutate(
    obj1 = scale_obj(obj1),
    obj2 = scale_obj(obj2),
    obj3 = scale_obj(obj3)
  ) %>%
ggpairs(columns = 1:3)
```

This is a very interesting plot that highlights the complexity of analyzing Pareto fronts in dimensions higher than 3. When looking at obj1 vs obj2 and obj1 vs obj3, we see some non-Pareto front shapes. These are the optimal trade-offs, but they don't look optimal because we are not considering all 3 objectives. Is obj2 vs obj3 some special situation because it maintains the Pareto front shape? We see the univariate distributions of efficiencies. For obj1 and obj2, we only really see good and bad solutions. Hard to see how low the design efficiencies would actually be because of the scaling. For obj3, we see that a large proportion of the front is does well at obj3.

```{r}
# explore the designs
extract_front(result) %>%
  mutate(
    obj1 = scale_obj(obj1),
    obj2 = scale_obj(obj2),
    obj3 = scale_obj(obj3)
  ) %>%
  arrange((obj3))
```

The major difference between the (obj1, obj2) cluster and the obj3 cluster is that theta3 requires dose groups (0, 30, 50) while (theta1, theta2) needs (0, 13 or 16, 27 or 30).

## Designs with model uncertainty

In many cases, we may want to apply multiple models to the data. We want to make sure our design will be efficient for estimating all the models that we want to use.

Because the models in my code are parameterized the same as in BMDS, we will get parameter estimates from BMDS.

### Log-logistic vs. Weibull

```{r}
# fit log-logistic and Weibull models to data
#mod1 = drm(r/n ~ dose, weights=n, data=deguelin, fct=LL.3u(), type='binomial')
#mod2 = drm(r/n ~ dose, weights=n, data=deguelin, fct=W1.3u(), type='binomial')

data.frame(
  dose = seq(0, 50)
) %>%
  mutate(
    yhat1 = f.loglogistic3.bmds(dose, c(0.3238, -12.09, 4.137)),
    yhat2 = f.weibull3.bmds(dose, c(0.2414, 1.805, 0.004269))
    ) %>%
  ggplot(aes(x = dose)) +
  geom_line(aes(y = yhat1), color='red') +
  geom_line(aes(y = yhat2), color = 'blue') +
  geom_point(data=drc::deguelin, aes(x = dose, y = r/n), color = 'black') +
  theme_bw() +
  labs(y = 'P(death)', title = 'Effect of deguelin on Macrosiphoniella sanborni')
```

```{r}
# design for log-logistic
out_loglogistic = nlodm(
  grad_fun = grad.loglogistic,
  obj = "D",
  theta = c(0.3238, -12.09, 4.137),
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 100,
  iter = 500,
  seed = 423,
  binary_response = T,
  dr_fun = f.loglogistic3.bmds
)
```

```{r}
# design for Weibull
out_weibull = nlodm(
  grad_fun = grad.weibull,
  obj = "D",
  theta = c(0.2414, 1.805, 0.004269),
  bound = 50,
  pts = 3,
  algorithm = 'DE',
  swarm = 100,
  iter = 500,
  seed = 423,
  binary_response = T,
  dr_fun = f.weibull3.bmds
)
```

```{r}
out_loglogistic$design
```

```{r}
out_weibull$design
```

```{r}
grad_funs = list(grad.loglogistic, grad.weibull)
obj_funs = list(obj.D, obj.D)
thetas = list(
    c(0.3238, -12.09, 4.137),
    c(0.2414, 1.805, 0.004269)
  )
params = list(
    c(),
    c()
  )
binary_responses = c(T,T)
dr_funs = list(f.loglogistic3.bmds, f.weibull3.bmds)

result_ll_w = multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
extract_front(result_ll_w) %>%
  plot_pareto2d(c('Log-logistic', 'Weibull')) +
  geom_smooth(se = F, linetype = 2, color = 'grey')
```

```{r}
extract_front(result_ll_w) %>%
  mutate(
    obj1 = scale_obj(obj1),
    obj2 = scale_obj(obj2)
  ) %>%
  plot_pareto2d(c('Log-logistic', 'Weibull')) +
  geom_smooth(se = F, linetype = 2, color = 'grey') +
  annotate('point', x = 1, y = 1, color = 'red')
```

### More models

```{r}
data.frame(
  dose = seq(0, 50)
) %>%
  mutate(
    loglogistic = f.loglogistic3.bmds(dose, c(0.3238, -12.09, 4.137)),
    weibull = f.weibull3.bmds(dose, c(0.2414, 1.805, 0.004269)),
    hill = f.hill.bmds(dose, c(0.3238, 0.99, -12.09, 4.137)),
    multistage1 = f.multi1.bmds(dose, c(0.0001, 0.07127)),
    logistic = f.logistic.bmds(dose, c(-1.563, 0.1258)),
    logprobit = f.logprobit.bmds(dose, c(0.3139, -6.442, 2.220)),
    probit = f.probit.bmds(dose, c(-0.8824, 0.07047))
    ) %>%
  pivot_longer(
    cols = -dose,
    names_to = 'model'
  ) %>%
  ggplot(aes(x = dose, y = value, color = model)) +
  geom_line()+
  geom_point(data=drc::deguelin, aes(x = dose, y = r/n), color = 'black') +
  theme_bw() +
  labs(y = 'P(death)', title = 'Effect of deguelin on Macrosiphoniella sanborni')
```

```{r}
grad_funs = list(grad.loglogistic, grad.weibull, grad.hill, grad.multi1,
                 grad.logistic, grad.logprobit, grad.probit)
obj_funs = list(obj.D, obj.D, obj.D, obj.D, obj.D, obj.D, obj.D)
thetas = list(
    c(0.3238, -12.09, 4.137),
    c(0.2414, 1.805, 0.004269),
    c(0.3238, 0.99, -12.09, 4.137),
    c(0.0001, 0.07127),
    c(-1.563, 0.1258),
    c(0.3139, -6.442, 2.220),
    c(-0.8824, 0.07047)
  )
params = list(
    c(),
    c(),
    c(),
    c(),
    c(),
    c(),
    c()
  )
binary_responses = rep(T, 7)
dr_funs = list(f.loglogistic3.bmds, f.weibull3.bmds, f.hill.bmds, 
               f.multi1.bmds, f.logistic.bmds, f.logprobit.bmds, f.probit.bmds)

result_all_models= multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 3,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
extract_front(result_all_models)
```

```{r}
extract_front(result_all_models) %>%
  mutate(
    loglogistic = scale_obj(obj1),
    weibull = scale_obj(obj2),
    hill = scale_obj(obj3),
    multistage1 = scale_obj(obj4),
    logistic = scale_obj(obj5),
    logprobit = scale_obj(obj6),
    probit = scale_obj(obj7),
  ) %>%
ggpairs(columns = 14:20)
```

It is really complicated to interpret 10 different objectives. Interesting to see which variables have a linear trend. What does the linear trend signify. Log-logistic vs Weibull, log-logistic vs log-probit, log-probit vs Weibull, logistic vs probit.

Now look at histograms. It seems that most designs are not good for the Hill model and most are good for logistic and probit. This is likely because we only considered designs with 3 points for a 4 parameter model. What does this plot look like when we allow for a max of 4 design points?

```{r}

grad_funs = list(grad.loglogistic, grad.weibull, grad.hill, grad.multi1,
                 grad.logistic, grad.logprobit, grad.probit)
obj_funs = list(obj.D, obj.D, obj.D, obj.D, obj.D, obj.D, obj.D)
thetas = list(
    c(0.3238, -12.09, 4.137),
    c(0.2414, 1.805, 0.004269),
    c(0.3238, 0.99, -12.09, 4.137),
    c(0.0001, 0.07127),
    c(-1.563, 0.1258),
    c(0.3139, -6.442, 2.220),
    c(-0.8824, 0.07047)
  )
params = list(
    c(),
    c(),
    c(),
    c(),
    c(),
    c(),
    c()
  )
binary_responses = rep(T, 7)
dr_funs = list(f.loglogistic3.bmds, f.weibull3.bmds, f.hill.bmds, 
               f.multi1.bmds, f.logistic.bmds, f.logprobit.bmds, f.probit.bmds)

result_all_models4= multi_obj(
    grad_funs = grad_funs,
    obj_funs = obj_funs,
    thetas = thetas,
    params = params,
    type = 'pareto',
    bound = 50,
    pts = 4,
    swarm = 100,
    maxiter = 500,
    verbose = F,
    exact = F,
    binary_responses = binary_responses,
    dr_funs = dr_funs
  )
```

```{r}
extract_front(result_all_models4) %>%
  mutate(
    loglogistic = scale_obj(obj1),
    weibull = scale_obj(obj2),
    hill = scale_obj(obj3),
    multistage1 = scale_obj(obj4),
    logistic = scale_obj(obj5),
    logprobit = scale_obj(obj6),
    probit = scale_obj(obj7),
  ) %>%
ggpairs(columns = 16:22)
```

This is better, but we still see that the Hill model has different needs because it needs the 4 support points. Let's look at the best designs for the Hill model.

```{r}
extract_front(result_all_models4) %>%
  mutate(
    loglogistic = scale_obj(obj1),
    weibull = scale_obj(obj2),
    hill = scale_obj(obj3),
    multistage1 = scale_obj(obj4),
    logistic = scale_obj(obj5),
    logprobit = scale_obj(obj6),
    probit = scale_obj(obj7),
  ) %>%
  arrange(desc(hill)) %>%
  select(hill, starts_with('d'), starts_with('w'))
```

We see that 4 dose groups are needed. Compare this to the designs for the log-logistic.

```{r}
extract_front(result_all_models4) %>%
  mutate(
    loglogistic = scale_obj(obj1),
    weibull = scale_obj(obj2),
    hill = scale_obj(obj3),
    multistage1 = scale_obj(obj4),
    logistic = scale_obj(obj5),
    logprobit = scale_obj(obj6),
    probit = scale_obj(obj7),
  ) %>%
  arrange(desc(loglogistic)) %>%
  select(loglogistic, starts_with('d'), starts_with('w'))
```

These are not the optimal design, but we can see that two of the dose groups are close together and roughly split the 0.33 weight. Now let's look at the logistic model.

```{r}
extract_front(result_all_models4) %>%
  mutate(
    loglogistic = scale_obj(obj1),
    weibull = scale_obj(obj2),
    hill = scale_obj(obj3),
    multistage1 = scale_obj(obj4),
    logistic = scale_obj(obj5),
    logprobit = scale_obj(obj6),
    probit = scale_obj(obj7),
  ) %>%
  arrange(desc(logistic)) %>%
  select(logistic, starts_with('d'), starts_with('w'))
```

The best designs here suggest the two dose group design, which is the optimal design for the two parameter models.
